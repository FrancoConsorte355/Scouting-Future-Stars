{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerías a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import kaggle\n",
    "from sqlalchemy import create_engine \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTOMATIZACIÓN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "DBAPIError",
     "evalue": "(pyodbc.Error) ('HY104', '[HY104] [Microsoft][ODBC SQL Server Driver]Valor de precisión no válido (0) (SQLBindParameter)')\n[SQL: SELECT [INFORMATION_SCHEMA].[TABLES].[TABLE_NAME] \nFROM [INFORMATION_SCHEMA].[TABLES] \nWHERE ([INFORMATION_SCHEMA].[TABLES].[TABLE_TYPE] = CAST(? AS NVARCHAR(max)) OR [INFORMATION_SCHEMA].[TABLES].[TABLE_TYPE] = CAST(? AS NVARCHAR(max))) AND [INFORMATION_SCHEMA].[TABLES].[TABLE_NAME] = CAST(? AS NVARCHAR(max)) AND [INFORMATION_SCHEMA].[TABLES].[TABLE_SCHEMA] = CAST(? AS NVARCHAR(max))]\n[parameters: ('BASE TABLE', 'VIEW', 'common_player_info', 'dbo')]\n(Background on this error at: https://sqlalche.me/e/20/dbapi)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 941\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mError\u001b[0m: ('HY104', '[HY104] [Microsoft][ODBC SQL Server Driver]Valor de precisión no válido (0) (SQLBindParameter)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDBAPIError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 64\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArchivo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv no encontrado en la ruta de descarga.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Paso 1: Descargar los datos desde Kaggle\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Aquí debes implementar la descarga con Kaggle si es necesario\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Paso 2: Cargar los datos relevantes en SQL\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[43mload_relevant_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 56\u001b[0m, in \u001b[0;36mload_relevant_data\u001b[1;34m(download_path, engine)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(data_path):\n\u001b[0;32m     55\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_path)\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mload_to_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArchivo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv no encontrado en la ruta de descarga.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 35\u001b[0m, in \u001b[0;36mload_to_sql\u001b[1;34m(table_name, data, engine)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m     33\u001b[0m     data[column] \u001b[38;5;241m=\u001b[39m data[column]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[:\u001b[38;5;241m255\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x)\n\u001b[1;32m---> 35\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatos cargados en la tabla \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2891\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3083\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\sql.py:842\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    839\u001b[0m     )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\sql.py:2008\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1959\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   1960\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;124;03m    Any additional kwargs are passed to the engine.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2006\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m-> 2008\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2016\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2018\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m sql_engine\u001b[38;5;241m.\u001b[39minsert_records(\n\u001b[0;32m   2019\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m   2020\u001b[0m     con\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2027\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m   2028\u001b[0m )\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\sql.py:1912\u001b[0m, in \u001b[0;36mSQLDatabase.prep_table\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, dtype)\u001b[0m\n\u001b[0;32m   1900\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe type of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a SQLAlchemy type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1902\u001b[0m table \u001b[38;5;241m=\u001b[39m SQLTable(\n\u001b[0;32m   1903\u001b[0m     name,\n\u001b[0;32m   1904\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1910\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1911\u001b[0m )\n\u001b[1;32m-> 1912\u001b[0m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\sql.py:984\u001b[0m, in \u001b[0;36mSQLTable.create\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 984\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfail\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    986\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\sql.py:970\u001b[0m, in \u001b[0;36mSQLTable.exists\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexists\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpd_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\sql.py:2041\u001b[0m, in \u001b[0;36mSQLDatabase.has_table\u001b[1;34m(self, name, schema)\u001b[0m\n\u001b[0;32m   2038\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inspect \u001b[38;5;28;01mas\u001b[39;00m sqlalchemy_inspect\n\u001b[0;32m   2040\u001b[0m insp \u001b[38;5;241m=\u001b[39m sqlalchemy_inspect(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon)\n\u001b[1;32m-> 2041\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minsp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\reflection.py:438\u001b[0m, in \u001b[0;36mInspector.has_table\u001b[1;34m(self, table_name, schema, **kw)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return True if the backend has a table, view, or temporary\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03mtable of the given name.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    435\u001b[0m \n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation_context() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\dialects\\mssql\\base.py:2854\u001b[0m, in \u001b[0;36m_db_plus_owner.<locals>.wrap\u001b[1;34m(dialect, connection, tablename, schema, **kw)\u001b[0m\n\u001b[0;32m   2852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(dialect, connection, tablename, schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m   2853\u001b[0m     dbname, owner \u001b[38;5;241m=\u001b[39m _owner_plus_db(dialect, schema)\n\u001b[1;32m-> 2854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_switch_db\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2858\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2859\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2860\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtablename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mowner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2864\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2865\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\dialects\\mssql\\base.py:2878\u001b[0m, in \u001b[0;36m_switch_db\u001b[1;34m(dbname, connection, fn, *arg, **kw)\u001b[0m\n\u001b[0;32m   2874\u001b[0m         connection\u001b[38;5;241m.\u001b[39mexec_driver_sql(\n\u001b[0;32m   2875\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m connection\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39midentifier_preparer\u001b[38;5;241m.\u001b[39mquote(dbname)\n\u001b[0;32m   2876\u001b[0m         )\n\u001b[0;32m   2877\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2879\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dbname \u001b[38;5;129;01mand\u001b[39;00m current_db \u001b[38;5;241m!=\u001b[39m dbname:\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\dialects\\mssql\\base.py:3267\u001b[0m, in \u001b[0;36mMSDialect.has_table\u001b[1;34m(self, connection, tablename, dbname, owner, schema, **kw)\u001b[0m\n\u001b[0;32m   3263\u001b[0m \u001b[38;5;129m@_db_plus_owner\u001b[39m\n\u001b[0;32m   3264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_table\u001b[39m(\u001b[38;5;28mself\u001b[39m, connection, tablename, dbname, owner, schema, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m   3265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_has_table_connection(connection)\n\u001b[1;32m-> 3267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_has_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtablename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36m_internal_has_table\u001b[1;34m(self, connection, tablename, owner, **kw)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\reflection.py:106\u001b[0m, in \u001b[0;36mcache\u001b[1;34m(fn, self, con, *args, **kw)\u001b[0m\n\u001b[0;32m    104\u001b[0m ret: _R \u001b[38;5;241m=\u001b[39m info_cache\u001b[38;5;241m.\u001b[39mget(key)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     info_cache[key] \u001b[38;5;241m=\u001b[39m ret\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\dialects\\mssql\\base.py:3370\u001b[0m, in \u001b[0;36mMSDialect._internal_has_table\u001b[1;34m(self, connection, tablename, owner, **kw)\u001b[0m\n\u001b[0;32m   3367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m owner:\n\u001b[0;32m   3368\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mwhere(tables\u001b[38;5;241m.\u001b[39mc\u001b[38;5;241m.\u001b[39mtable_schema \u001b[38;5;241m==\u001b[39m owner)\n\u001b[1;32m-> 3370\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\u001b[38;5;241m.\u001b[39mfirst() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1628\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[0;32m   1630\u001b[0m )\n\u001b[0;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1639\u001b[0m )\n\u001b[1;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[0;32m   1654\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1655\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1659\u001b[0m         ret,\n\u001b[0;32m   1660\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2355\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2354\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2357\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1965\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[0;32m   1972\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1973\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1974\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1978\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   1979\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 941\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mDBAPIError\u001b[0m: (pyodbc.Error) ('HY104', '[HY104] [Microsoft][ODBC SQL Server Driver]Valor de precisión no válido (0) (SQLBindParameter)')\n[SQL: SELECT [INFORMATION_SCHEMA].[TABLES].[TABLE_NAME] \nFROM [INFORMATION_SCHEMA].[TABLES] \nWHERE ([INFORMATION_SCHEMA].[TABLES].[TABLE_TYPE] = CAST(? AS NVARCHAR(max)) OR [INFORMATION_SCHEMA].[TABLES].[TABLE_TYPE] = CAST(? AS NVARCHAR(max))) AND [INFORMATION_SCHEMA].[TABLES].[TABLE_NAME] = CAST(? AS NVARCHAR(max)) AND [INFORMATION_SCHEMA].[TABLES].[TABLE_SCHEMA] = CAST(? AS NVARCHAR(max))]\n[parameters: ('BASE TABLE', 'VIEW', 'common_player_info', 'dbo')]\n(Background on this error at: https://sqlalche.me/e/20/dbapi)"
     ]
    }
   ],
   "source": [
    "# Configuración\n",
    "dataset_name = \"wyattowalsh/basketball\"\n",
    "download_path = \"C:/Users/Usuario/Documents/Analisis de datos/Modulos/Proyecto Final/csv\"\n",
    "db_connection_string = 'mssql+pyodbc://sa:26799franco@DESKTOP-H76NFOF/NBA_STATS?driver=SQL+Server'\n",
    "\n",
    "# Conexión a la base de datos SQL Server\n",
    "engine = create_engine(db_connection_string)\n",
    "\n",
    "# Función para verificar si existe una tabla\n",
    "def table_exists(engine, table_name, schema='dbo'):\n",
    "    query = f\"\"\"\n",
    "    SELECT 1\n",
    "    FROM INFORMATION_SCHEMA.TABLES\n",
    "    WHERE TABLE_SCHEMA = '{schema}' AND TABLE_NAME = '{table_name}'\n",
    "    \"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(query)).fetchone()  # text() asegura que la consulta sea ejecutable\n",
    "    return result is not None\n",
    "\n",
    "# Función para cargar los datos en la base de datos\n",
    "def load_to_sql(table_name, data, engine):\n",
    "    # Validar si la tabla existe\n",
    "    if not table_exists(engine, table_name):\n",
    "        print(f\"La tabla {table_name} no existe en la base de datos. Crea la tabla primero.\")\n",
    "        return\n",
    "\n",
    "    # Limitar la longitud de las columnas tipo texto (NVARCHAR)\n",
    "    for column in data.select_dtypes(include=['object']).columns:\n",
    "        data[column] = data[column].apply(lambda x: x[:255] if isinstance(x, str) else x)\n",
    "\n",
    "    data.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
    "    print(f\"Datos cargados en la tabla {table_name}.\")\n",
    "\n",
    "# Función para cargar los datos de las tablas importantes\n",
    "def load_relevant_data(download_path, engine):\n",
    "    tables_of_interest = [\n",
    "        'common_player_info',\n",
    "        'draft_combine_stats',\n",
    "        'draft_history',\n",
    "        'game',\n",
    "        'player',\n",
    "        'PlayerStatsSummary',\n",
    "        'team',\n",
    "        'team_details'\n",
    "    ]\n",
    "\n",
    "    # Cargar los archivos de datos relevantes y cargarlos en SQL\n",
    "    for table_name in tables_of_interest:\n",
    "        data_path = os.path.join(download_path, f\"{table_name}.csv\")\n",
    "        if os.path.exists(data_path):\n",
    "            data = pd.read_csv(data_path)\n",
    "            load_to_sql(table_name, data, engine)\n",
    "        else:\n",
    "            print(f\"Archivo {table_name}.csv no encontrado en la ruta de descarga.\")\n",
    "\n",
    "# Paso 1: Descargar los datos desde Kaggle\n",
    "# Aquí debes implementar la descarga con Kaggle si es necesario\n",
    "\n",
    "# Paso 2: Cargar los datos relevantes en SQL\n",
    "load_relevant_data(download_path, engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, exc, text\n",
    "import datetime\n",
    "import os\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "# Configuración de la cadena de conexión con la base de datos\n",
    "server = 'DESKTOP-H76NFOF'  # Cambia esto por tu servidor\n",
    "database = 'NBA_STATS'  # Cambia esto por tu base de datos\n",
    "username = 'sa'  # Cambia esto por tu usuario de base de datos\n",
    "password = '26799franco'  # Cambia esto por tu contraseña\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "try:\n",
    "    engine = create_engine(f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server')\n",
    "    conn = engine.connect()\n",
    "except exc.SQLAlchemyError as e:\n",
    "    print(f\"Error al conectar a la base de datos: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Definimos una clase que maneja los eventos de modificación en el sistema de archivos\n",
    "class MyHandler(FileSystemEventHandler):\n",
    "    def __init__(self, observer, ruta_datos):\n",
    "        self.observer = observer\n",
    "        self.ruta_datos = ruta_datos\n",
    "        # Mapa que asocia archivos CSV con la tabla de base de datos correspondiente y la columna a utilizar para la comparación\n",
    "        self.table_map = {\n",
    "            r\"C:\\Users\\Usuario\\Documents\\Analisis de datos\\Modulos\\Proyecto Final\\csv\\game.csv\": ('game', 'game_id'),\n",
    "            r\"C:\\C:\\Users\\Usuario\\Documents\\Analisis de datos\\Modulos\\Proyecto Final\\csv\\player.csv\": ('player', 'id'),\n",
    "            # Añadir más mapeos si es necesario\n",
    "        }\n",
    "\n",
    "    # Método que se ejecuta cuando un archivo es modificado\n",
    "    def on_modified(self, event):\n",
    "        # Verifica si el archivo modificado es un archivo CSV\n",
    "        if event.src_path.endswith('.csv'):\n",
    "            print(f\"Archivo CSV modificado: {event.src_path}\")\n",
    "            # Lee el archivo CSV modificado en un DataFrame de pandas\n",
    "            df = pd.read_csv(event.src_path, dtype={self.table_map[event.src_path][1]: float}, header=0)\n",
    "            # Obtiene el nombre de la tabla y la columna principal desde el mapa de tablas\n",
    "            tabla, primera_columna = self.table_map.get(event.src_path, (None, None))\n",
    "            print(f\"Procesando la tabla : {tabla}, usando la columna {primera_columna}\")\n",
    "            print(f\"Columnas en el DataFrame: {df.columns.tolist()}\")\n",
    "\n",
    "            # Si se encuentra una tabla y una columna asociada\n",
    "            if tabla and primera_columna:\n",
    "                # Llama al método para ingresar los datos en la base de datos\n",
    "                self.ingresar_datos(df, tabla, primera_columna)\n",
    "                # Detiene el observador después de procesar el archivo\n",
    "                self.observer.stop()\n",
    "            else:\n",
    "                print(f\"No se encontró una tabla asociada para {event.src_path}\")\n",
    "\n",
    "    # Método para ingresar los datos nuevos en la base de datos\n",
    "    def ingresar_datos(self, df, tabla, primera_columna):\n",
    "        try:\n",
    "            # Obtiene el último id de ingesta desde la tabla ingestion_control\n",
    "            query = f\"SELECT MAX(last_ingestion_id) AS last_id FROM ingestion_control WHERE table_name = '{tabla}'\"\n",
    "            last_ingestion_id = pd.read_sql(query, conn).iloc[0, 0]\n",
    "            last_ingestion_id = last_ingestion_id if last_ingestion_id is not None else 0\n",
    "            print(f\"Comparando valores en la columna {primera_columna} con last_ingestion_id: {last_ingestion_id}\")\n",
    "            print(f\"Valores en la columna {primera_columna}:\\n{df[primera_columna].head()}\")\n",
    "\n",
    "            # Filtra los datos nuevos comparando con el último id de ingesta\n",
    "            new_data = df[df[primera_columna] > last_ingestion_id].copy()\n",
    "            print(f\"Nuevos datos encontrados para la tabla {tabla}:\\n{new_data}\")\n",
    "\n",
    "            # Asigna el valor de last_ingestion_id a los nuevos datos\n",
    "            new_data['last_ingestion_id'] = new_data[primera_columna]\n",
    "\n",
    "            # Si hay nuevos datos, se insertan en la base de datos\n",
    "            if not new_data.empty:\n",
    "                # Inserta los nuevos datos en la tabla correspondiente\n",
    "                new_data.to_sql(tabla, engine, if_exists='append', index=False)\n",
    "\n",
    "                # Obtiene el máximo id procesado en los nuevos datos\n",
    "                last_processed_id = int(new_data[primera_columna].max())\n",
    "\n",
    "                # Inserta el nuevo registro en la tabla ingestion_control\n",
    "                insert_query = text(\"\"\"\n",
    "                    INSERT INTO ingestion_control (last_ingestion_id, created_at, updated_at, table_name)\n",
    "                    VALUES (:last_ingestion_id, :created_at, :updated_at, :table_name)\n",
    "                \"\"\")\n",
    "                # Ejecuta la inserción en la base de datos dentro de una transacción\n",
    "                with engine.begin() as connection:\n",
    "                    connection.execute(insert_query, {\n",
    "                        'last_ingestion_id': last_processed_id,\n",
    "                        'created_at': datetime.datetime.now(),\n",
    "                        'updated_at': datetime.datetime.now(),\n",
    "                        'table_name': tabla\n",
    "                    })\n",
    "                print(\"Datos ingresados con éxito en la tabla y en ingestion_control\")\n",
    "\n",
    "            else:\n",
    "                # Si no hay datos nuevos, imprime un mensaje indicando que no hay nada para insertar\n",
    "                print(\"No hay nuevos datos para insertar.\")\n",
    "        except exc.SQLAlchemyError as e:\n",
    "            # Captura cualquier error de SQLAlchemy y lo imprime\n",
    "            print(f\"Error durante la ingesta de datos: {e}\")\n",
    "\n",
    "# Bloque principal de ejecución del script\n",
    "if __name__ == \"__main__\":\n",
    "    # Define la ruta donde se monitorearán los archivos\n",
    "    ruta_datos = r\"C:\\Users\\Usuario\\Documents\\Analisis de datos\\Modulos\\Proyecto Final\\csv\"\n",
    "    # Crea una instancia del observador de archivos\n",
    "    observer = Observer()\n",
    "    # Asocia el manejador de eventos con el observador\n",
    "    event_handler = MyHandler(observer, ruta_datos)\n",
    "    # Programa el observador para monitorear la ruta definida y sus subdirectorios\n",
    "    observer.schedule(event_handler, ruta_datos, recursive=True)\n",
    "    # Inicia el observador\n",
    "    observer.start()\n",
    "\n",
    "    # Mantiene el script en ejecución hasta que el observador sea detenido\n",
    "    observer.join()\n",
    "    print(\"Proceso de monitoreo finalizado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzando la verificación de la automatización...\n",
      "No se detectaron cambios en los archivos. Verifica la automatización.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "def verificar_automatizacion(directorio_observado):\n",
    "    try:\n",
    "        # Monitorear la carpeta durante un tiempo\n",
    "        print(\"Comenzando la verificación de la automatización...\")\n",
    "        archivos_antes = set(os.listdir(directorio_observado))\n",
    "        time.sleep(5)  # Espera 5 segundos para detectar cambios\n",
    "        archivos_despues = set(os.listdir(directorio_observado))\n",
    "\n",
    "        # Compara los archivos antes y después de la espera\n",
    "        if archivos_antes != archivos_despues:\n",
    "            print(\"¡Automatización funcionando! Se detectaron cambios en los archivos.\")\n",
    "        else:\n",
    "            print(\"No se detectaron cambios en los archivos. Verifica la automatización.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Hubo un error al verificar la automatización: {e}\")\n",
    "\n",
    "# Cambia esto por el directorio que estás monitoreando\n",
    "directorio = r\"C:\\Users\\Usuario\\Documents\\Analisis de datos\\Modulos\\Proyecto Final\\csv\"\n",
    "verificar_automatizacion(directorio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzando la verificación de la automatización...\n",
      "No se detectaron cambios en los archivos. Verifica la automatización.\n",
      "¡Ingesta de datos exitosa! Hay registros en la base de datos.\n",
      "Hubo un problema con la automatización. Verifica el proceso.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, exc\n",
    "\n",
    "# Configuración de la cadena de conexión con la base de datos\n",
    "server = 'DESKTOP-H76NFOF'  # Cambia esto por tu servidor\n",
    "database = 'NBA_STATS'  # Cambia esto por tu base de datos\n",
    "username = 'sa'  # Cambia esto por tu usuario de base de datos\n",
    "password = '26799franco'  # Cambia esto por tu contraseña\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "# Función para verificar los cambios en los archivos CSV\n",
    "def verificar_archivos(directorio_observado):\n",
    "    try:\n",
    "        archivos_antes = set(os.listdir(directorio_observado))\n",
    "        time.sleep(5)  # Espera 5 segundos para detectar cambios\n",
    "        archivos_despues = set(os.listdir(directorio_observado))\n",
    "\n",
    "        if archivos_antes != archivos_despues:\n",
    "            print(\"¡Automatización funcionando! Se detectaron cambios en los archivos.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"No se detectaron cambios en los archivos. Verifica la automatización.\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Hubo un error al verificar la automatización: {e}\")\n",
    "        return False\n",
    "\n",
    "# Función para verificar si los datos fueron insertados en la base de datos\n",
    "def verificar_ingesta_datos():\n",
    "    try:\n",
    "        # Conexión a la base de datos\n",
    "        engine = create_engine(f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server')\n",
    "        conn = engine.connect()\n",
    "\n",
    "        # Verificar si se ha insertado al menos un registro en una de las tablas\n",
    "        query = \"SELECT COUNT(*) FROM game\"  # Cambia 'game' por la tabla que estés utilizando\n",
    "        result = pd.read_sql(query, conn)\n",
    "\n",
    "        if result.iloc[0, 0] > 0:\n",
    "            print(\"¡Ingesta de datos exitosa! Hay registros en la base de datos.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"No se encontraron registros en la base de datos. Verifica la ingesta de datos.\")\n",
    "            return False\n",
    "\n",
    "    except exc.SQLAlchemyError as e:\n",
    "        print(f\"Error al conectar a la base de datos: {e}\")\n",
    "        return False\n",
    "\n",
    "# Verificación completa del proceso de automatización\n",
    "def verificar_proceso_automatizacion(directorio_observado):\n",
    "    print(\"Comenzando la verificación de la automatización...\")\n",
    "\n",
    "    # Verificar cambios en los archivos CSV\n",
    "    archivos_verificados = verificar_archivos(directorio_observado)\n",
    "    \n",
    "    # Verificar si los datos fueron ingresados en la base de datos\n",
    "    ingesta_verificada = verificar_ingesta_datos()\n",
    "\n",
    "    if archivos_verificados and ingesta_verificada:\n",
    "        print(\"La automatización está funcionando correctamente.\")\n",
    "    else:\n",
    "        print(\"Hubo un problema con la automatización. Verifica el proceso.\")\n",
    "\n",
    "# Cambia esto por el directorio que estás monitoreando\n",
    "directorio = r\"C:\\Users\\Usuario\\Documents\\Analisis de datos\\Modulos\\Proyecto Final\\csv\"\n",
    "verificar_proceso_automatizacion(directorio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, exc, text\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# Configuración de la base de datos\n",
    "CONFIG = {\n",
    "    'server': 'DESKTOP-H76NFOF',  # Cambia esto por tu servidor\n",
    "    'database': 'NBA_STATS',      # Cambia esto por tu base de datos\n",
    "    'username': 'sa',             # Cambia esto por tu usuario\n",
    "    'password': '26799franco',    # Cambia esto por tu contraseña\n",
    "    'driver': 'ODBC+Driver+17+for+SQL+Server',\n",
    "    'data_dir': r\"C:\\Users\\Usuario\\Documents\\Analisis de datos\\Modulos\\Proyecto Final\\csv\"  # Directorio de los CSV\n",
    "}\n",
    "\n",
    "# Crear conexión con la base de datos\n",
    "def create_db_engine(config):\n",
    "    try:\n",
    "        connection_string = f\"mssql+pyodbc://{config['username']}:{config['password']}@{config['server']}/{config['database']}?driver={config['driver']}\"\n",
    "        engine = create_engine(connection_string)\n",
    "        print(\"Conexión a la base de datos establecida con éxito.\")\n",
    "        return engine\n",
    "    except exc.SQLAlchemyError as e:\n",
    "        print(f\"Error al conectar a la base de datos: {e}\")\n",
    "        exit()\n",
    "\n",
    "# Carga incremental de datos\n",
    "def cargar_datos_csv(engine, file_path, tabla, primary_column):\n",
    "    try:\n",
    "        # Leer datos del archivo CSV\n",
    "        df = pd.read_csv(file_path, dtype={primary_column: float}, header=0)\n",
    "        print(f\"Procesando archivo: {file_path} para la tabla {tabla}.\")\n",
    "        \n",
    "        # Obtener el último ID procesado desde la tabla de control\n",
    "        query = f\"SELECT MAX(last_ingestion_id) AS last_id FROM ingestion_control WHERE table_name = '{tabla}'\"\n",
    "        last_ingestion_id = pd.read_sql(query, engine).iloc[0, 0]\n",
    "        last_ingestion_id = last_ingestion_id if last_ingestion_id is not None else 0\n",
    "\n",
    "        # Filtrar solo los datos nuevos\n",
    "        nuevos_datos = df[df[primary_column] > last_ingestion_id].copy()\n",
    "\n",
    "        if not nuevos_datos.empty:\n",
    "            # Insertar los nuevos datos en la tabla\n",
    "            nuevos_datos.to_sql(tabla, engine, if_exists='append', index=False)\n",
    "\n",
    "            # Actualizar la tabla de control con el último ID procesado\n",
    "            last_processed_id = int(nuevos_datos[primary_column].max())\n",
    "            insert_query = text(\"\"\"\n",
    "                INSERT INTO ingestion_control (last_ingestion_id, created_at, updated_at, table_name)\n",
    "                VALUES (:last_ingestion_id, :created_at, :updated_at, :table_name)\n",
    "            \"\"\")\n",
    "            with engine.begin() as connection:\n",
    "                connection.execute(insert_query, {\n",
    "                    'last_ingestion_id': last_processed_id,\n",
    "                    'created_at': datetime.datetime.now(),\n",
    "                    'updated_at': datetime.datetime.now(),\n",
    "                    'table_name': tabla\n",
    "                })\n",
    "            print(f\"Datos nuevos cargados en la tabla {tabla}. Último ID procesado: {last_processed_id}.\")\n",
    "        else:\n",
    "            print(f\"No hay datos nuevos para la tabla {tabla}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar datos desde {file_path} a la tabla {tabla}: {e}\")\n",
    "\n",
    "# Monitoreo de cambios en el directorio\n",
    "def monitorear_cambios(engine, config, table_map):\n",
    "    archivos_procesados = set()  # Mantener seguimiento de archivos ya procesados\n",
    "    print(\"Iniciando monitoreo de directorio...\")\n",
    "    while True:\n",
    "        try:\n",
    "            # Listar los archivos en el directorio\n",
    "            archivos_actuales = set(os.listdir(config['data_dir']))\n",
    "            nuevos_archivos = archivos_actuales - archivos_procesados\n",
    "\n",
    "            for archivo in nuevos_archivos:\n",
    "                file_path = os.path.join(config['data_dir'], archivo)\n",
    "                if file_path in table_map:\n",
    "                    tabla, primary_column = table_map[file_path]\n",
    "                    cargar_datos_csv(engine, file_path, tabla, primary_column)\n",
    "                else:\n",
    "                    print(f\"Archivo {archivo} no está mapeado a ninguna tabla.\")\n",
    "                archivos_procesados.add(archivo)\n",
    "\n",
    "            # Esperar antes de revisar nuevamente\n",
    "            time.sleep(10)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Monitoreo detenido manualmente.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error durante el monitoreo: {e}\")\n",
    "\n",
    "# Mapa de archivos CSV a tablas y columnas primarias\n",
    "TABLE_MAP = {\n",
    "    r\"C:\\Users\\Usuario\\Documents\\Analisis de datos\\Modulos\\Proyecto Final\\csv\\game.csv\": ('game', 'game_id'),\n",
    "    r\"C:\\Users\\Usuario\\Documents\\Analisis de datos\\Modulos\\Proyecto Final\\csv\\player.csv\": ('player', 'id'),\n",
    "    # Añade más archivos si es necesario\n",
    "}\n",
    "\n",
    "# Ejecución principal\n",
    "if __name__ == \"__main__\":\n",
    "    # Crear conexión a la base de datos\n",
    "    engine = create_db_engine(CONFIG)\n",
    "\n",
    "    # Iniciar monitoreo del directorio y carga incremental\n",
    "    monitorear_cambios(engine, CONFIG, TABLE_MAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:04:58,882 [INFO] Monitoreo iniciado. Presiona Ctrl+C para detener.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import logging\n",
    "from sqlalchemy import create_engine, exc, text\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "# Configuración de conexión a la base de datos\n",
    "DB_CONFIG = {\n",
    "    'server': 'DESKTOP-H76NFOF',  # Cambiar por tu servidor\n",
    "    'database': 'NBA_STATS',      # Cambiar por tu base de datos\n",
    "    'username': 'sa',             # Cambiar por tu usuario\n",
    "    'password': '26799franco',    # Cambiar por tu contraseña\n",
    "    'driver': '{ODBC Driver 17 for SQL Server}'\n",
    "}\n",
    "\n",
    "# Configuración de ruta de datos\n",
    "DATA_PATH = r\"C:\\Users\\Usuario\\Documents\\Analisis de datos\\Modulos\\Proyecto Final\\csv\"\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# Crear conexión a la base de datos\n",
    "def get_engine():\n",
    "    try:\n",
    "        engine = create_engine(\n",
    "            f\"mssql+pyodbc://{DB_CONFIG['username']}:{DB_CONFIG['password']}@{DB_CONFIG['server']}/{DB_CONFIG['database']}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        return engine\n",
    "    except exc.SQLAlchemyError as e:\n",
    "        logging.error(f\"Error al conectar a la base de datos: {e}\")\n",
    "        raise\n",
    "\n",
    "# Clase para manejar eventos de modificación\n",
    "class FileEventHandler(FileSystemEventHandler):\n",
    "    def __init__(self, engine, table_map):\n",
    "        self.engine = engine\n",
    "        self.table_map = table_map\n",
    "\n",
    "    def on_modified(self, event):\n",
    "        if event.src_path.endswith(\".csv\"):\n",
    "            logging.info(f\"Archivo modificado: {event.src_path}\")\n",
    "            self.process_file(event.src_path)\n",
    "\n",
    "    def process_file(self, file_path):\n",
    "        try:\n",
    "            # Validar si el archivo está mapeado\n",
    "            if file_path not in self.table_map:\n",
    "                logging.warning(f\"Archivo no mapeado: {file_path}\")\n",
    "                return\n",
    "\n",
    "            table_name, primary_column = self.table_map[file_path]\n",
    "            logging.info(f\"Procesando tabla: {table_name} | Columna clave: {primary_column}\")\n",
    "\n",
    "            # Cargar archivo CSV\n",
    "            df = pd.read_csv(file_path)\n",
    "            if df.empty:\n",
    "                logging.info(f\"No hay datos en el archivo: {file_path}\")\n",
    "                return\n",
    "\n",
    "            # Ingresar datos en la base de datos\n",
    "            self.ingest_data(df, table_name, primary_column)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al procesar el archivo {file_path}: {e}\")\n",
    "\n",
    "    def ingest_data(self, df, table_name, primary_column):\n",
    "        try:\n",
    "            # Obtener el último ID de ingesta\n",
    "            query = f\"SELECT MAX(last_ingestion_id) AS last_id FROM ingestion_control WHERE table_name = '{table_name}'\"\n",
    "            last_ingestion_id = pd.read_sql(query, self.engine).iloc[0, 0]\n",
    "            last_ingestion_id = last_ingestion_id if last_ingestion_id is not None else 0\n",
    "\n",
    "            # Filtrar nuevos datos\n",
    "            new_data = df[df[primary_column] > last_ingestion_id].copy()\n",
    "            if new_data.empty:\n",
    "                logging.info(f\"No hay nuevos datos para insertar en la tabla {table_name}.\")\n",
    "                return\n",
    "\n",
    "            # Insertar nuevos datos en la tabla\n",
    "            new_data['last_ingestion_id'] = new_data[primary_column]\n",
    "            with self.engine.begin() as connection:\n",
    "                new_data.to_sql(table_name, connection, if_exists='append', index=False)\n",
    "\n",
    "                # Actualizar la tabla de control de ingestas\n",
    "                last_processed_id = int(new_data[primary_column].max())\n",
    "                insert_query = text(\"\"\"\n",
    "                    INSERT INTO ingestion_control (last_ingestion_id, created_at, updated_at, table_name)\n",
    "                    VALUES (:last_ingestion_id, :created_at, :updated_at, :table_name)\n",
    "                \"\"\")\n",
    "                connection.execute(insert_query, {\n",
    "                    'last_ingestion_id': last_processed_id,\n",
    "                    'created_at': datetime.datetime.now(),\n",
    "                    'updated_at': datetime.datetime.now(),\n",
    "                    'table_name': table_name\n",
    "                })\n",
    "            logging.info(f\"Ingesta completada para la tabla {table_name}.\")\n",
    "        except exc.SQLAlchemyError as e:\n",
    "            logging.error(f\"Error durante la ingesta de datos: {e}\")\n",
    "\n",
    "# Bloque principal\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        engine = get_engine()\n",
    "        table_map = {\n",
    "            os.path.join(DATA_PATH, \"game.csv\"): ('game', 'game_id'),\n",
    "            os.path.join(DATA_PATH, \"player.csv\"): ('player', 'id'),\n",
    "            # Agregar más mapeos si es necesario\n",
    "        }\n",
    "\n",
    "        event_handler = FileEventHandler(engine, table_map)\n",
    "        observer = Observer()\n",
    "        observer.schedule(event_handler, DATA_PATH, recursive=True)\n",
    "        observer.start()\n",
    "\n",
    "        logging.info(\"Monitoreo iniciado. Presiona Ctrl+C para detener.\")\n",
    "        observer.join()\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"Monitoreo detenido por el usuario.\")\n",
    "        observer.stop()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error general: {e}\")\n",
    "    finally:\n",
    "        observer.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import logging\n",
    "from sqlalchemy import create_engine, exc, text\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 17:49:54,024 [INFO] Monitoreo iniciado. Presiona Ctrl+C para detener.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import logging\n",
    "from sqlalchemy import create_engine, exc, text\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "# Configuración de conexión a la base de datos\n",
    "DB_CONFIG = {\n",
    "    'server': 'DESKTOP-H76NFOF',  # Cambiar por tu servidor\n",
    "    'database': 'NBA_STATS',      # Cambiar por tu base de datos\n",
    "    'username': 'sa',             # Cambiar por tu usuario\n",
    "    'password': '26799franco',    # Cambiar por tu contraseña\n",
    "    'driver': '{ODBC Driver 17 for SQL Server}'\n",
    "}\n",
    "\n",
    "# Configuración de ruta de datos\n",
    "DATA_PATH = r\"C:\\Users\\Usuario\\Documents\\Analisis de datos\\Modulos\\Proyecto Final\\csv\"\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# Crear conexión a la base de datos\n",
    "def get_engine():\n",
    "    try:\n",
    "        engine = create_engine(\n",
    "            f\"mssql+pyodbc://{DB_CONFIG['username']}:{DB_CONFIG['password']}@{DB_CONFIG['server']}/{DB_CONFIG['database']}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        return engine\n",
    "    except exc.SQLAlchemyError as e:\n",
    "        logging.error(f\"Error al conectar a la base de datos: {e}\")\n",
    "        raise\n",
    "\n",
    "# Clase para manejar eventos de modificación\n",
    "class OptimizedFileEventHandler(FileSystemEventHandler):\n",
    "    def __init__(self, engine, table_map):\n",
    "        self.engine = engine\n",
    "        self.table_map = table_map\n",
    "        self.last_processed_files = {}  # Registro del último timestamp de archivos procesados\n",
    "\n",
    "    def on_modified(self, event):\n",
    "        if event.src_path.endswith(\".csv\"):\n",
    "            logging.info(f\"Archivo modificado detectado: {event.src_path}\")\n",
    "            self.process_file(event.src_path)\n",
    "\n",
    "    def process_file(self, file_path):\n",
    "        try:\n",
    "            # Validar si el archivo está mapeado\n",
    "            if file_path not in self.table_map:\n",
    "                logging.warning(f\"Archivo no mapeado: {file_path}\")\n",
    "                return\n",
    "\n",
    "            # Obtener la tabla y la columna clave\n",
    "            table_name, primary_column = self.table_map[file_path]\n",
    "\n",
    "            # Validar si el archivo ya fue procesado recientemente\n",
    "            last_mod_time = os.path.getmtime(file_path)\n",
    "            if file_path in self.last_processed_files and self.last_processed_files[file_path] == last_mod_time:\n",
    "                logging.info(f\"El archivo {file_path} ya fue procesado. Saltando...\")\n",
    "                return\n",
    "\n",
    "            # Cargar los datos nuevos desde el archivo CSV\n",
    "            df = pd.read_csv(file_path)\n",
    "            if df.empty:\n",
    "                logging.info(f\"No hay datos en el archivo: {file_path}\")\n",
    "                return\n",
    "\n",
    "            # Ingresar datos nuevos en la base de datos\n",
    "            self.ingest_data(df, table_name, primary_column)\n",
    "\n",
    "            # Actualizar el registro del último timestamp procesado\n",
    "            self.last_processed_files[file_path] = last_mod_time\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al procesar el archivo {file_path}: {e}\")\n",
    "\n",
    "    def ingest_data(self, df, table_name, primary_column):\n",
    "        try:\n",
    "            # Obtener el último ID procesado desde la tabla de control\n",
    "            query = f\"SELECT MAX(last_ingestion_id) AS last_id FROM ingestion_control WHERE table_name = '{table_name}'\"\n",
    "            last_ingestion_id = pd.read_sql(query, self.engine).iloc[0, 0]\n",
    "            last_ingestion_id = last_ingestion_id if last_ingestion_id is not None else 0\n",
    "\n",
    "            # Filtrar datos nuevos\n",
    "            new_data = df[df[primary_column] > last_ingestion_id].copy()\n",
    "            if new_data.empty:\n",
    "                logging.info(f\"No hay nuevos datos para insertar en la tabla {table_name}.\")\n",
    "                return\n",
    "\n",
    "            # Insertar los datos nuevos\n",
    "            with self.engine.begin() as connection:\n",
    "                new_data.to_sql(table_name, connection, if_exists='append', index=False)\n",
    "\n",
    "                # Actualizar la tabla de control\n",
    "                last_processed_id = int(new_data[primary_column].max())\n",
    "                insert_query = text(\"\"\"\n",
    "                    INSERT INTO ingestion_control (last_ingestion_id, created_at, updated_at, table_name)\n",
    "                    VALUES (:last_ingestion_id, :created_at, :updated_at, :table_name)\n",
    "                \"\"\")\n",
    "                connection.execute(insert_query, {\n",
    "                    'last_ingestion_id': last_processed_id,\n",
    "                    'created_at': datetime.datetime.now(),\n",
    "                    'updated_at': datetime.datetime.now(),\n",
    "                    'table_name': table_name\n",
    "                })\n",
    "            logging.info(f\"Ingesta completada para la tabla {table_name}.\")\n",
    "        except exc.SQLAlchemyError as e:\n",
    "            logging.error(f\"Error durante la ingesta de datos: {e}\")\n",
    "\n",
    "# Bloque principal\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        engine = get_engine()\n",
    "        table_map = {\n",
    "            os.path.join(DATA_PATH, \"game.csv\"): ('game', 'game_id'),\n",
    "            os.path.join(DATA_PATH, \"player.csv\"): ('player', 'id'),\n",
    "            # Agregar más mapeos si es necesario\n",
    "        }\n",
    "\n",
    "        event_handler = OptimizedFileEventHandler(engine, table_map)\n",
    "        observer = Observer()\n",
    "        observer.schedule(event_handler, DATA_PATH, recursive=False)  # No usa recursividad para optimizar\n",
    "        observer.start()\n",
    "\n",
    "        logging.info(\"Monitoreo iniciado. Presiona Ctrl+C para detener.\")\n",
    "        observer.join()\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"Monitoreo detenido por el usuario.\")\n",
    "        observer.stop()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error general: {e}\")\n",
    "    finally:\n",
    "        observer.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión exitosa a la base de datos.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "DB_CONFIG = {\n",
    "    'server': 'DESKTOP-H76NFOF',\n",
    "    'database': 'NBA_STATS',\n",
    "    'username': 'sa',\n",
    "    'password': '26799franco',\n",
    "    'driver': '{ODBC Driver 17 for SQL Server}'\n",
    "}\n",
    "\n",
    "def test_database_connection():\n",
    "    try:\n",
    "        # Crear conexión\n",
    "        engine = create_engine(\n",
    "            f\"mssql+pyodbc://{DB_CONFIG['username']}:{DB_CONFIG['password']}@{DB_CONFIG['server']}/{DB_CONFIG['database']}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        with engine.connect() as conn:\n",
    "            # Usa text para ejecutar la consulta\n",
    "            result = conn.execute(text(\"SELECT 1\")).fetchone()\n",
    "            assert result[0] == 1, \"Consulta SQL no retornó el resultado esperado.\"\n",
    "            print(\"Conexión exitosa a la base de datos.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error en la conexión: {e}\")\n",
    "\n",
    "test_database_connection()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lectura de CSV exitosa.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def test_csv_loading():\n",
    "    try:\n",
    "        # Ruta corregida\n",
    "        test_file = r\"C:\\Users\\Usuario\\Documents\\Analisis de datos\\Modulos\\Proyecto Final\\csv\\game.csv\"\n",
    "        \n",
    "        # Leer el archivo CSV\n",
    "        df = pd.read_csv(test_file)\n",
    "        \n",
    "        # Verificar que no esté vacío\n",
    "        assert not df.empty, \"El archivo CSV está vacío.\"\n",
    "        print(\"Lectura de CSV exitosa.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error en la lectura de CSV: {e}\")\n",
    "\n",
    "test_csv_loading()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado incremental exitoso.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def test_incremental_load():\n",
    "    # Simula datos en el archivo CSV\n",
    "    csv_data = pd.DataFrame({'game_id': [1, 2, 3, 4, 5], 'data': ['a', 'b', 'c', 'd', 'e']})\n",
    "    last_ingestion_id = 3  # Último dato procesado\n",
    "    new_data = csv_data[csv_data['game_id'] > last_ingestion_id]\n",
    "    \n",
    "    assert len(new_data) == 2, f\"Se esperaban 2 filas nuevas, pero se obtuvieron {len(new_data)}\"\n",
    "    print(\"Filtrado incremental exitoso.\")\n",
    "\n",
    "test_incremental_load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión exitosa. Datasets populares disponibles:\n",
      "- Depression Student Dataset (ikynahidwin/depression-student-dataset)\n",
      "- Customer Shopping (Latest Trends) Dataset (bhadramohit/customer-shopping-latest-trends-dataset)\n",
      "- student lifestyle dataset (steve1215rogg/student-lifestyle-dataset)\n",
      "- Full IMDb Dataset (1M+) (octopusteam/full-imdb-dataset)\n",
      "- Depression Professional Dataset (ikynahidwin/depression-professional-dataset)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "def verificar_conexion_kaggle():\n",
    "    try:\n",
    "        # Configuración de la ruta al archivo kaggle.json\n",
    "        os.environ[\"KAGGLE_CONFIG_DIR\"] = os.path.expanduser(\"~/.kaggle\")\n",
    "\n",
    "        # Inicializar la API de Kaggle\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "\n",
    "        # Probar la conexión listando datasets populares\n",
    "        datasets = api.dataset_list(sort_by='hottest')\n",
    "        print(\"Conexión exitosa. Datasets populares disponibles:\")\n",
    "        for dataset in datasets[:5]:\n",
    "            print(f\"- {dataset.title} ({dataset.ref})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al conectar con la API de Kaggle: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    verificar_conexion_kaggle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión exitosa. El dataset 'wyattowalsh/basketball' está disponible en Kaggle.\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "def verify_connection(dataset):\n",
    "    try:\n",
    "        # Autenticar con la API de Kaggle\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        \n",
    "        # Buscar el dataset\n",
    "        datasets = api.dataset_list(search=dataset)\n",
    "        \n",
    "        # Verificar si el dataset existe\n",
    "        if any(ds.ref == dataset for ds in datasets):\n",
    "            print(f\"Conexión exitosa. El dataset '{dataset}' está disponible en Kaggle.\")\n",
    "        else:\n",
    "            print(f\"El dataset '{dataset}' no se encontró en Kaggle. Verifica el nombre.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error al conectar con la API de Kaggle:\", str(e))\n",
    "\n",
    "# Nombre del dataset a verificar\n",
    "dataset_name = \"wyattowalsh/basketball\"\n",
    "verify_connection(dataset_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 18:58:25,795 [INFO] Monitoreo iniciado. Presiona Ctrl+C para detener.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import logging\n",
    "from sqlalchemy import create_engine, exc, text\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "# Configuración de conexión a la base de datos\n",
    "DB_CONFIG = {\n",
    "    'server': 'DESKTOP-H76NFOF',  # Cambiar por tu servidor\n",
    "    'database': 'NBA_STATS',      # Cambiar por tu base de datos\n",
    "    'username': 'sa',             # Cambiar por tu usuario\n",
    "    'password': '26799franco',    # Cambiar por tu contraseña\n",
    "    'driver': '{ODBC Driver 17 for SQL Server}'\n",
    "}\n",
    "\n",
    "# Configuración de ruta de datos\n",
    "DATA_PATH = r\"C:\\Users\\Usuario\\Documents\\Analisis de datos\\Modulos\\Proyecto Final\\csv\"\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# Crear conexión a la base de datos\n",
    "def get_engine():\n",
    "    try:\n",
    "        engine = create_engine(\n",
    "            f\"mssql+pyodbc://{DB_CONFIG['username']}:{DB_CONFIG['password']}@{DB_CONFIG['server']}/{DB_CONFIG['database']}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        )\n",
    "        return engine\n",
    "    except exc.SQLAlchemyError as e:\n",
    "        logging.error(f\"Error al conectar a la base de datos: {e}\")\n",
    "        raise\n",
    "\n",
    "# Clase para manejar eventos de modificación\n",
    "class OptimizedFileEventHandler(FileSystemEventHandler):\n",
    "    def __init__(self, engine, table_map):\n",
    "        self.engine = engine\n",
    "        self.table_map = table_map\n",
    "        self.last_processed_files = {}  # Registro del último timestamp de archivos procesados\n",
    "\n",
    "    def on_modified(self, event):\n",
    "        if event.src_path.endswith(\".csv\"):\n",
    "            logging.info(f\"Archivo modificado detectado: {event.src_path}\")\n",
    "            self.process_file(event.src_path)\n",
    "\n",
    "    def process_file(self, file_path):\n",
    "        try:\n",
    "            # Validar si el archivo está mapeado\n",
    "            if file_path not in self.table_map:\n",
    "                logging.warning(f\"Archivo no mapeado: {file_path}\")\n",
    "                return\n",
    "\n",
    "            # Obtener la tabla y la columna clave\n",
    "            table_name, primary_column = self.table_map[file_path]\n",
    "\n",
    "            # Validar si el archivo ya fue procesado recientemente\n",
    "            last_mod_time = os.path.getmtime(file_path)\n",
    "            if file_path in self.last_processed_files and self.last_processed_files[file_path] == last_mod_time:\n",
    "                logging.info(f\"El archivo {file_path} ya fue procesado. Saltando...\")\n",
    "                return\n",
    "\n",
    "            # Cargar los datos nuevos desde el archivo CSV\n",
    "            df = pd.read_csv(file_path)\n",
    "            if df.empty:\n",
    "                logging.info(f\"No hay datos en el archivo: {file_path}\")\n",
    "                return\n",
    "\n",
    "            # Ingresar datos nuevos en la base de datos\n",
    "            self.ingest_data(df, table_name, primary_column)\n",
    "\n",
    "            # Actualizar el registro del último timestamp procesado\n",
    "            self.last_processed_files[file_path] = last_mod_time\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al procesar el archivo {file_path}: {e}\")\n",
    "\n",
    "    def ingest_data(self, df, table_name, primary_column):\n",
    "        try:\n",
    "            # Obtener el último ID procesado desde la tabla de control\n",
    "            query = f\"SELECT MAX(last_ingestion_id) AS last_id FROM ingestion_control WHERE table_name = '{table_name}'\"\n",
    "            last_ingestion_id = pd.read_sql(query, self.engine).iloc[0, 0]\n",
    "            last_ingestion_id = last_ingestion_id if last_ingestion_id is not None else 0\n",
    "\n",
    "            # Filtrar datos nuevos\n",
    "            new_data = df[df[primary_column] > last_ingestion_id].copy()\n",
    "            if new_data.empty:\n",
    "                logging.info(f\"No hay nuevos datos para insertar en la tabla {table_name}.\")\n",
    "                return\n",
    "\n",
    "            # Insertar los datos nuevos\n",
    "            with self.engine.begin() as connection:\n",
    "                new_data.to_sql(table_name, connection, if_exists='append', index=False)\n",
    "\n",
    "                # Actualizar la tabla de control\n",
    "                last_processed_id = int(new_data[primary_column].max())\n",
    "                insert_query = text(\"\"\"\n",
    "                    INSERT INTO ingestion_control (last_ingestion_id, created_at, updated_at, table_name)\n",
    "                    VALUES (:last_ingestion_id, :created_at, :updated_at, :table_name)\n",
    "                \"\"\")\n",
    "                connection.execute(insert_query, {\n",
    "                    'last_ingestion_id': last_processed_id,\n",
    "                    'created_at': datetime.datetime.now(),\n",
    "                    'updated_at': datetime.datetime.now(),\n",
    "                    'table_name': table_name\n",
    "                })\n",
    "            logging.info(f\"Ingesta completada para la tabla {table_name}.\")\n",
    "        except exc.SQLAlchemyError as e:\n",
    "            logging.error(f\"Error durante la ingesta de datos: {e}\")\n",
    "\n",
    "# Bloque principal\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        engine = get_engine()\n",
    "        table_map = {\n",
    "            os.path.join(DATA_PATH, \"game.csv\"): ('game', 'game_id'),\n",
    "            os.path.join(DATA_PATH, \"player.csv\"): ('player', 'id'),\n",
    "            # Agregar más mapeos si es necesario\n",
    "        }\n",
    "\n",
    "        event_handler = OptimizedFileEventHandler(engine, table_map)\n",
    "        observer = Observer()\n",
    "        observer.schedule(event_handler, DATA_PATH, recursive=False)  # No usa recursividad para optimizar\n",
    "        observer.start()\n",
    "\n",
    "        logging.info(\"Monitoreo iniciado. Presiona Ctrl+C para detener.\")\n",
    "        observer.join()\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"Monitoreo detenido por el usuario.\")\n",
    "        observer.stop()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error general: {e}\")\n",
    "    finally:\n",
    "        observer.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
